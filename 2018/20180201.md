-----
**Date : February 1, 2018**

**Venue : NUS**

**Group : NUS**

**Topic : Efficient Hardware for deep learning**

**Tags : deep learning hardware** 

**Speaker : Bill Dally, Nvidia**

----

Hardware and data enable deep neural networks 

For supervised you need large labelled datasets

For unsupervised/reinforcement - learn from the environment 

Performance gets better with More data, bigger models, more computation

As we go into new domains, amount of computation required also goes up . E.g from image to speech 

DNN primer 

Talks about GPUs : Volta V100 
For deep learning, they started supporting FP16 and FP8 on top of FP32 

Acc to Moores law, you would get 3 times the capability in the next processor, but recently you only get 1.2 times the capability - to improve further only way is to optimize for the particular application 

Core loop of all neural networks - matrix matrix multiplication 

Tensor core - mixed precision matrix math 

He claims nvidia Volta much faster than google TPUs 

For internet of things applications - they have new chip Xavier (AI supercomputer system on chip) - it has a deep learning accelerator (DLA)

Nvidia DLA - hes explaining the architecture - is more optimised for operations involved in DL 

Accelerators : EIE, SCNN

DLA has better energy efficiency than cuda, volta(cpu , fpga are much worse)

How to improve architecture for DL applications 
- use the lowest resolution that you can get away with
- trained quantization - refer Deep compression paper, arxiv 2015
- reduce the number of bits per weight without sacrificing accuracy 
- pruning to make the models smaller : refer paper -  Learning both weights and connections for efficient neural networks, NIPS 2015 

30 - 50x compression means complex DNNs can be put in mobile applications. 

Efficient communication 
- across multiple GPUs 
- data parallelism, gradient compression: do all of these together - gradient sparsification, local accumulation, local norm clipping, momentum correction(this is quite tricky), warm-up training 
- with the above, 200-600x savings in communication BW for both images and speech 

Sparse matrix representation, sparse convolution engine 

AI for graphics applications 
- for game character rendering - reduces 100s hours of artist time 
- material modelling - reduces 100s hours of artist time
- AI denoising : potentially move ray tracing to realtime
- anti aliasing 
- progressive GAN : train it on simple things first and progressively increase the image size -better quality and convergence

Feature engineering by deep learning 

Manual feature engineering is less effective than learning features in most endeavors - use visualisation tools for interpretability