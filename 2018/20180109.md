-----
**Date : January 9, 2018**

**Venue : Microsoft Auditorium**

**Group : PyData**

**Topic : From Scikit-learn to TensorFlow Estimators**

**Tags : machine learning, deep learning, scikit-learn, tensorflow** 

**Speaker : Karthik MSwamy, SAP Singapore**

----

code: http://bit.ly/tfest-scikit

Tensorflow estimators, canned estimators

juxtapose scikit-learn and tensorflow estimators 

Recently google revamped the tenforflow framework to reduce the barrier to entry 

TF ESTIMATORS

TF estimators has a similar API as scikit, scikit preprocessing pipeline is independent of TF 

(new) TF i/p functions - pass features, target data (train, predict, evaluate), allows feature engineering / pre-processing inside the function 

TF estimators makes it easy to port TF models to production in TF Serving 

- summary stuff like writing to files becomes easier

There are premade estimators (canned estimators) - only need to call the wrapper function, also can create custom one

keras also updated into the tf.keras paradigm, so you can now import your previous keras code into TF
(refer speaker's blog or github) - in this case, you get the pros of running TF on distributed systems plus access to tensorboard etc

Typical workflow with pre-made estimators 
- write datset import functions
- define feature columns
- instantiate premade estimator
- call train, evaluate or inference methods 

Workflow for custom estimator 
- evaluate using a premade estimator - baseline 
- evaluate overall pipeline 
- try more premade estimators 
- imporve and evaluate custom model

TIP: use a single performance measure to evaluate models  

he also uses FACETS to visualise features, exploratry analysis and checking out the distributions 

You can use Tensorboard to check speed of input pipeline etc even when the model is running 

Takeaways
- understand the problem 
- get your stats right, visualise data 
- treat test data with utmost respect: dont touch test data - you cannot look at test data and then go back and train, split train to train and validation if you want to do cross validation - dont touch test data 
- experiment fast, fail fast 
- log experimental parameters and results always 
- plan for scalability 
- test on new domains : if you have an estimator - then you just switch the data pipeline, dont change the estimator params and check the performance 

there is an experiments function in TF - to log different params and show in tensorboard 

pytorch follows a more python style approach - in tensorflow 1.5 eager will be similar to pytorch approach
