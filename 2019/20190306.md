-----
**Date : December 6, 2019**

**Venue : Suntec City**

**Group : DataX Singapore**

**Topic : Topics from Day 2**

**Tags : data science, machine learning, AI** 

----

*Speaker: Jason Tamara Widjaja (MSD) *<br>
*Topic: Addressing Privacy and Untangling Bias for Responsible AI*

- More Data != Better models. Biased data leads to biased models. 
- Lack of human oversight for automated decisions 
- Black box models 

Systematic discrimination : allocation harm and representation harm 

PDPC releases proposed model AI Governance Framework 
Framing the Problem (PDPC Guidelines)

- De-biasing AI is not the job of only data scientists/AI team 
- What is a fair model?
- Choose your features consciously 

Explainable AI 
- Trade predictive power for more explanable models 
- Check for systematic bias of different levels
- Introduce forensics and explainability (LIME framework)
- Focus on data interpretation 

Course: Data Privacy and Anonymisation in R 

Takeaway points 
- start with encryption, "with great visibility comes great liability"
- think through how you process images/videos 
- redesign the consent experience 

Source of bias: You. AI systems are designed to optimise for a goal. 
We decide on this goal. 


----

*Speaker: Grace Tang (Netflix) *<br>
*Topic: Combining Human and Artificial Intelligence for a Personalised Experience*

Sunspring (AI generated screenplay)

Use case: Displaying optimal artwork for the Netflix titles 

Domain experts work with data scientists to explain why certain images performed better than others 
Use expert knowledge for features selection in using automated frames from the video as artwork 

- A/B testing: high regret and unpersonalised 
- To lower regret, use multi-armed bandit but this is still not personalised
- To make it personalised, use contexual bandit 

----

*Speaker: Alok Kumar (DBS Bank) *<br>
*Topic: Smart ATM withdrawal Recommendation Engine*

Use cases 
1. Cash forecasting and scheduling for predicting cash-outs 
2. Recommendation engine to recommend alternate amount instead of cashout 

ATM transactions 
- 300 million transactions per year, 7.2% of transactions used to fail 
- it took around 2 years to optimise the learning model to reach zero cashouts 
- With the recommendation engine, 97% customers accepted the alternate amount

Takeaway points 
- Data will never be perfect, strat now and build incrementally 
- Integrate data and design techniques 
- Focus on preventing the problem more than solving it 

----